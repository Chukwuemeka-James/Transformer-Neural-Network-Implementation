# Transformer From Scratch ‚Äì CodeEmporium

This project is a hands-on studio based on the **"Transformer from Scratch"** playlist by **CodeEmporium**. It recreates the complete transformer neural network architecture from the ground up using PyTorch, explained step by step through intuitive, interactive Jupyter notebooks.

## Project Objective

To break down the internals of the Transformer model‚Äîincluding self-attention, positional encoding, encoder-decoder blocks, and training‚Äîinto digestible parts for easier learning and experimentation.

## Repository Structure

| File/Folder | Description |
|-------------|-------------|
| `dataset/` | Contains the training dataset used for model experimentation |
| `01_Self_Attention_for_Transformer_Neural_Networks.ipynb` | Introduction to Self-Attention mechanism |
| `02_Mutlihead_Attention.ipynb` | Implementation of Multi-Head Attention |
| `03_Positional_Encoding_in_Transformer_neural_networks.ipynb` | Adding positional encoding to the input embeddings |
| `04_Layer_Normalization.ipynb` | Understanding and implementing Layer Normalization |
| `05_Transformer_Encoder.ipynb` | Implementation of the Transformer Encoder |
| `06_Transformer_Decoder.ipynb` | Implementation of the Transformer Decoder |
| `07_Sentence_Tokenization.ipynb` | Sentence tokenization techniques and tokenizer setup |
| `09_Transformer_Trainer_Notebook.ipynb` | Full training loop for the transformer model |
| `LICENSE` | Project license |
| `README.md` | Project documentation (this file) |


## Use Cases

- Learning resource for deep NLP concepts
- Research experimentation with modular Transformer components
- Showcase project for interviews and portfolios

## üôè Acknowledgment

This project is heavily inspired by the **"Transformer from Scratch"** playlist by [**CodeEmporium**](https://www.youtube.com/@CodeEmporium).  
Watch the full playlist here:  
[Transformer from Scratch Playlist](https://youtube.com/playlist?list=PLZV1qtTjOY4vGmiNhyF4E_f3nWj2X5XYW&si=H1v8Omgz1vL_FylB)

I highly recommend watching the accompanying video:  
üé• [Transformer Neural Networks Explained](https://youtu.be/QCJQG4DuHT0?si=kqeat8YgYhbBniUm)