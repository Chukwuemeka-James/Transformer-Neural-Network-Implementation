{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Add and Norm in the Attention Architecture**\n",
        "\n",
        "The **Add and Norm** step is a key component in the Transformer architecture, particularly in the **Encoder** and **Decoder** layers. It is designed to stabilize the learning process and facilitate the flow of gradients during backpropagation. Here's what it does:\n",
        "\n",
        "---\n",
        "\n",
        "### **1. Add: Residual Connection**\n",
        "- The **Add** operation implements a **residual connection**, which helps mitigate the vanishing gradient problem and accelerates training. \n",
        "- The output of a sub-layer (e.g., Self-Attention or Feed-Forward Network) is **added** to the input of that sub-layer.\n",
        "\n",
        "---\n",
        "\n",
        "### **2. Norm: Layer Normalization**\n",
        "- After the residual connection, **Layer Normalization** is applied to the combined output to ensure that activations are normalized.\n",
        "\n",
        "### **Key Benefits of Add and Norm**\n",
        "1. **Stabilized Training:**\n",
        "   - Layer normalization ensures consistent scaling of activations across layers.\n",
        "2. **Efficient Gradient Flow:**\n",
        "   - Residual connections improve gradient flow during backpropagation, allowing deeper architectures to train effectively.\n",
        "3. **Improved Representation Learning:**\n",
        "   - Residual connections let the model focus on learning refinements over identity mappings.\n",
        "\n",
        "---\n",
        "\n",
        "### **Add and Norm in Transformer Layers**\n",
        "In a Transformer layer, **Add and Norm** is applied twice:\n",
        "1. **After the Multi-Head Attention Sub-layer:**\n",
        "   - Combines the attention output with the input embedding or previous layer's output.\n",
        "2. **After the Feed-Forward Sub-layer:**\n",
        "   - Combines the feed-forward output with the result from the previous Add and Norm step.\n",
        "\n",
        "### **Layer Normalization in Transformers**\n",
        "\n",
        "**Layer Normalization (LayerNorm)** is a normalization technique used in Transformer models to stabilize and accelerate training. It operates at the level of individual training examples and normalizes the activations within a layer to have a mean of 0 and a standard deviation of 1. Here's a detailed breakdown:\n",
        "\n",
        "---\n",
        "### How Does LayerNorm Work?\n",
        "Given a vector of activations \\( x \\) at a specific layer, LayerNorm computes:\n",
        "\n",
        "$$\n",
        "\\text{LayerNorm}(x) = \\gamma \\cdot \\frac{x - \\mu}{\\sqrt{\\sigma^2 + \\epsilon}} + \\beta\n",
        "$$\n",
        "- **μ:** Mean of the activations across the layer.\n",
        "- **σ ^2:** Variance of the activations across the layer.\n",
        "- **ϵ:** A small constant to prevent division by zero.\n",
        "- **γ,β:** Learnable parameters (scale and shift) that allow the model to restore capacity after normalization.\n",
        "\n",
        "---\n",
        "\n",
        "### **LayerNorm in Transformers**\n",
        "1. **Placement in the Architecture:**\n",
        "   - In the Transformer, LayerNorm is typically applied **before or after each sub-layer** (self-attention or feed-forward network).\n",
        "   - For example, in \"Pre-Norm\" Transformers, LayerNorm is applied before the sub-layer, while in \"Post-Norm\" Transformers, it's applied after.\n",
        "\n",
        "2. **Benefits for Self-Attention:**\n",
        "   - Self-attention involves computing weighted sums of embeddings, which can have high variance. LayerNorm ensures these values are scaled appropriately.\n",
        "\n",
        "3. **Contrast with BatchNorm:**\n",
        "   - Unlike Batch Normalization, which normalizes over a batch of examples, LayerNorm operates independently for each training example, making it more suitable for sequential data like text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "yauMbbQbJ5Jk"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TL65EVE_J7KO",
        "outputId": "0d0ecb69-bc6b-4c26-91ea-15647d304287"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([2, 1, 3])"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "inputs = torch.Tensor([[[0.2, 0.1, 0.3], [0.5, 0.1, 0.1]]])\n",
        "B, S, E = inputs.size()\n",
        "inputs = inputs.reshape(S, B, E)\n",
        "inputs.size()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The reshape is necessary to reorder the dimensions of the tensor from **([B, S, E]\\) to ([S, B, E]),** which aligns with the expected input format for Transformer layers or operations like Multi-Head Attention. This order ensures compatibility with sequence-processing operations and standardizes the data pipeline. While the size remains the same, the dimensional layout adapts for downstream tasks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "--zvWWq2KLl1"
      },
      "outputs": [],
      "source": [
        "parameter_shape = inputs.size()[-2:]\n",
        "gamma = nn.Parameter(torch.ones(parameter_shape))\n",
        "beta =  nn.Parameter(torch.zeros(parameter_shape))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YAhmuOruKYzO",
        "outputId": "755d29b3-cfcf-42d0-ccce-6ffb09efd696"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([1, 3]), torch.Size([1, 3]))"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gamma.size(), beta.size()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "85ajY22cJ5Bg"
      },
      "outputs": [],
      "source": [
        "dims = [-(i + 1) for i in range(len(parameter_shape))]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "APG-ccQ1J4zc",
        "outputId": "5c2ad65e-9740-42b5-bfd2-dfa7ed3fc24a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[-1, -2]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dims"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Py8DHV7AMX6y",
        "outputId": "a897c5fc-a53c-497e-faae-c1c6cee49098"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([2, 1, 1])"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mean = inputs.mean(dim=dims, keepdim=True)\n",
        "mean.size()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P4w9NIUPQRj-",
        "outputId": "97fca7ec-f26b-4429-ff4c-197ac2c5d970"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[0.2000]],\n",
              "\n",
              "        [[0.2333]]])"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1lEkVVi3M_8_",
        "outputId": "f4e2a32b-d5ed-4622-8923-eb380d5b5bfc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[0.0817]],\n",
              "\n",
              "        [[0.1886]]])"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "var = ((inputs - mean) ** 2).mean(dim=dims, keepdim=True)\n",
        "epsilon = 1e-5\n",
        "std = (var + epsilon).sqrt()\n",
        "std"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rRokYqlDN6yJ",
        "outputId": "f6dcbaf3-ad33-4d9f-e0ec-039e49424e4a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[ 0.0000, -1.2238,  1.2238]],\n",
              "\n",
              "        [[ 1.4140, -0.7070, -0.7070]]])"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y = (inputs - mean) / std\n",
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "7cc8NMZVN_sQ"
      },
      "outputs": [],
      "source": [
        "out = gamma * y + beta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YquX9ABbOLKy",
        "outputId": "1bc33d96-e9e5-4a5d-e3cc-4cb9c89cea22"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[ 0.0000, -1.2238,  1.2238]],\n",
              "\n",
              "        [[ 1.4140, -0.7070, -0.7070]]], grad_fn=<AddBackward0>)"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BO4x-axkv9j8"
      },
      "source": [
        "## Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "MYJ2AE7Sv-Wc"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "class LayerNormalization():\n",
        "    def __init__(self, parameters_shape, eps=1e-5):\n",
        "        self.parameters_shape=parameters_shape\n",
        "        self.eps=eps\n",
        "        self.gamma = nn.Parameter(torch.ones(parameters_shape))\n",
        "        self.beta =  nn.Parameter(torch.zeros(parameters_shape))\n",
        "\n",
        "    def forward(self, input):\n",
        "        dims = [-(i + 1) for i in range(len(self.parameters_shape))]\n",
        "        mean = inputs.mean(dim=dims, keepdim=True)\n",
        "        print(f\"Mean \\n ({mean.size()}): \\n {mean}\")\n",
        "        var = ((inputs - mean) ** 2).mean(dim=dims, keepdim=True)\n",
        "        std = (var + self.eps).sqrt()\n",
        "        print(f\"Standard Deviation \\n ({std.size()}): \\n {std}\")\n",
        "        y = (inputs - mean) / std\n",
        "        print(f\"y \\n ({y.size()}) = \\n {y}\")\n",
        "        out = self.gamma * y  + self.beta\n",
        "        print(f\"out \\n ({out.size()}) = \\n {out}\")\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zrnZx0HYyoRz",
        "outputId": "7d894aa6-6181-4597-b160-a932fc274d70"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "input \n",
            " (torch.Size([5, 3, 8])) = \n",
            " tensor([[[ 8.3799e-01,  1.5723e+00, -9.5514e-01, -1.4994e+00,  7.0361e-01,\n",
            "           1.0687e+00,  2.3581e+00,  1.9513e+00],\n",
            "         [-4.6570e-01, -6.9836e-01, -6.4936e-01, -5.9919e-02,  6.3958e-01,\n",
            "           2.6308e-01,  3.1458e-01, -1.7177e-01],\n",
            "         [-1.5075e-01,  3.0940e-01,  1.3171e-01, -1.1500e+00,  5.6917e-01,\n",
            "           1.1410e+00,  8.0574e-04, -6.1830e-01]],\n",
            "\n",
            "        [[-3.3019e-01, -4.3450e-01,  3.8669e-02,  5.5271e-01, -5.4959e-01,\n",
            "          -1.2138e+00,  1.6253e+00,  5.1907e-01],\n",
            "         [ 1.6160e+00,  1.1097e-01,  7.0581e-01, -1.5954e+00, -6.9436e-01,\n",
            "          -1.4114e+00, -1.5395e+00, -9.0551e-01],\n",
            "         [ 1.2125e-01,  3.6788e-01,  4.3097e-01,  1.8649e-01, -1.4047e+00,\n",
            "          -8.2758e-01, -4.0525e-01, -3.6059e-01]],\n",
            "\n",
            "        [[-2.6711e+00,  9.5854e-01, -1.6292e+00,  5.0002e-02,  4.1646e-01,\n",
            "           5.0564e-01, -7.7049e-01, -1.5622e+00],\n",
            "         [-1.0538e+00,  1.2483e+00, -1.0638e-01, -4.7291e-01,  5.2497e-01,\n",
            "          -2.4971e-01,  9.1431e-01, -4.0231e-01],\n",
            "         [-1.0283e+00,  8.8972e-01,  1.2171e+00,  7.6288e-01,  1.8189e+00,\n",
            "           3.2267e-01, -8.1287e-01,  4.4578e-02]],\n",
            "\n",
            "        [[-3.7265e-01,  3.0446e-01, -1.5667e+00, -8.5146e-01,  2.4607e+00,\n",
            "          -3.0595e-01, -1.0135e+00, -5.6241e-01],\n",
            "         [-1.1045e+00,  1.6634e+00, -3.3825e-01, -1.5984e+00,  3.2933e-01,\n",
            "          -4.9067e-01,  7.8848e-01,  1.3093e+00],\n",
            "         [ 3.1685e-01,  5.8300e-01,  1.6113e+00, -2.2055e-01, -1.7634e-01,\n",
            "          -6.3896e-01,  5.2408e-01,  4.6435e-01]],\n",
            "\n",
            "        [[ 8.5345e-02,  4.5391e-01, -1.0306e+00,  5.6246e-01, -2.6213e-01,\n",
            "          -2.3439e+00, -1.6239e+00,  9.8065e-01],\n",
            "         [-4.1911e-01,  1.6728e+00,  2.6892e-01, -1.7358e-01,  5.5345e-01,\n",
            "          -2.7968e-01,  2.1484e+00, -1.8757e-02],\n",
            "         [ 5.1574e-01, -1.7520e+00, -4.3678e-01,  1.0904e-01, -2.7193e-01,\n",
            "          -2.4555e-01,  1.5379e-01,  2.8123e-01]]])\n"
          ]
        }
      ],
      "source": [
        "batch_size = 3\n",
        "sentence_length = 5\n",
        "embedding_dim = 8 \n",
        "inputs = torch.randn(sentence_length, batch_size, embedding_dim)\n",
        "\n",
        "print(f\"input \\n ({inputs.size()}) = \\n {inputs}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "3U3akvkFys68"
      },
      "outputs": [],
      "source": [
        "layer_norm = LayerNormalization(inputs.size()[-1:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JQ9lt7LUy-g9",
        "outputId": "658ed727-ec37-4eee-fef8-e553cb084e88"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean \n",
            " (torch.Size([5, 3, 1])): \n",
            " tensor([[[ 0.7547],\n",
            "         [-0.1035],\n",
            "         [ 0.0291]],\n",
            "\n",
            "        [[ 0.0260],\n",
            "         [-0.4642],\n",
            "         [-0.2364]],\n",
            "\n",
            "        [[-0.5878],\n",
            "         [ 0.0503],\n",
            "         [ 0.4018]],\n",
            "\n",
            "        [[-0.2384],\n",
            "         [ 0.0698],\n",
            "         [ 0.3080]],\n",
            "\n",
            "        [[-0.3973],\n",
            "         [ 0.4691],\n",
            "         [-0.2058]]])\n",
            "Standard Deviation \n",
            " (torch.Size([5, 3, 1])): \n",
            " tensor([[[1.2641],\n",
            "         [0.4543],\n",
            "         [0.6576]],\n",
            "\n",
            "        [[0.8129],\n",
            "         [1.0959],\n",
            "         [0.5996]],\n",
            "\n",
            "        [[1.1942],\n",
            "         [0.7262],\n",
            "         [0.9149]],\n",
            "\n",
            "        [[1.1428],\n",
            "         [1.0783],\n",
            "         [0.6380]],\n",
            "\n",
            "        [[1.0892],\n",
            "         [0.8886],\n",
            "         [0.6554]]])\n",
            "y \n",
            " (torch.Size([5, 3, 8])) = \n",
            " tensor([[[ 0.0659,  0.6468, -1.3526, -1.7831, -0.0404,  0.2484,  1.2684,\n",
            "           0.9466],\n",
            "         [-0.7973, -1.3095, -1.2016,  0.0959,  1.6357,  0.8069,  0.9203,\n",
            "          -0.1503],\n",
            "         [-0.2735,  0.4262,  0.1560, -1.7930,  0.8212,  1.6908, -0.0431,\n",
            "          -0.9845]],\n",
            "\n",
            "        [[-0.4382, -0.5665,  0.0156,  0.6480, -0.7081, -1.5252,  1.9676,\n",
            "           0.6066],\n",
            "         [ 1.8982,  0.5248,  1.0676, -1.0322, -0.2101, -0.8643, -0.9813,\n",
            "          -0.4027],\n",
            "         [ 0.5966,  1.0079,  1.1132,  0.7054, -1.9486, -0.9859, -0.2815,\n",
            "          -0.2071]],\n",
            "\n",
            "        [[-1.7445,  1.2948, -0.8720,  0.5341,  0.8409,  0.9156, -0.1530,\n",
            "          -0.8159],\n",
            "         [-1.5203,  1.6496, -0.2158, -0.7205,  0.6536, -0.4131,  1.1897,\n",
            "          -0.6233],\n",
            "         [-1.5632,  0.5333,  0.8911,  0.3946,  1.5489, -0.0865, -1.3277,\n",
            "          -0.3905]],\n",
            "\n",
            "        [[-0.1174,  0.4750, -1.1622, -0.5364,  2.3618, -0.0591, -0.6782,\n",
            "          -0.2835],\n",
            "         [-1.0890,  1.4778, -0.3785, -1.5470,  0.2406, -0.5198,  0.6664,\n",
            "           1.1494],\n",
            "         [ 0.0139,  0.4311,  2.0429, -0.8284, -0.7591, -1.4843,  0.3388,\n",
            "           0.2451]],\n",
            "\n",
            "        [[ 0.4431,  0.7815, -0.5814,  0.8811,  0.1241, -1.7873, -1.1262,\n",
            "           1.2651],\n",
            "         [-0.9995,  1.3547, -0.2252, -0.7232,  0.0950, -0.8426,  1.8899,\n",
            "          -0.5490],\n",
            "         [ 1.1009, -2.3592, -0.3524,  0.4804, -0.1009, -0.0606,  0.5487,\n",
            "           0.7431]]])\n",
            "out \n",
            " (torch.Size([5, 3, 8])) = \n",
            " tensor([[[ 0.0659,  0.6468, -1.3526, -1.7831, -0.0404,  0.2484,  1.2684,\n",
            "           0.9466],\n",
            "         [-0.7973, -1.3095, -1.2016,  0.0959,  1.6357,  0.8069,  0.9203,\n",
            "          -0.1503],\n",
            "         [-0.2735,  0.4262,  0.1560, -1.7930,  0.8212,  1.6908, -0.0431,\n",
            "          -0.9845]],\n",
            "\n",
            "        [[-0.4382, -0.5665,  0.0156,  0.6480, -0.7081, -1.5252,  1.9676,\n",
            "           0.6066],\n",
            "         [ 1.8982,  0.5248,  1.0676, -1.0322, -0.2101, -0.8643, -0.9813,\n",
            "          -0.4027],\n",
            "         [ 0.5966,  1.0079,  1.1132,  0.7054, -1.9486, -0.9859, -0.2815,\n",
            "          -0.2071]],\n",
            "\n",
            "        [[-1.7445,  1.2948, -0.8720,  0.5341,  0.8409,  0.9156, -0.1530,\n",
            "          -0.8159],\n",
            "         [-1.5203,  1.6496, -0.2158, -0.7205,  0.6536, -0.4131,  1.1897,\n",
            "          -0.6233],\n",
            "         [-1.5632,  0.5333,  0.8911,  0.3946,  1.5489, -0.0865, -1.3277,\n",
            "          -0.3905]],\n",
            "\n",
            "        [[-0.1174,  0.4750, -1.1622, -0.5364,  2.3618, -0.0591, -0.6782,\n",
            "          -0.2835],\n",
            "         [-1.0890,  1.4778, -0.3785, -1.5470,  0.2406, -0.5198,  0.6664,\n",
            "           1.1494],\n",
            "         [ 0.0139,  0.4311,  2.0429, -0.8284, -0.7591, -1.4843,  0.3388,\n",
            "           0.2451]],\n",
            "\n",
            "        [[ 0.4431,  0.7815, -0.5814,  0.8811,  0.1241, -1.7873, -1.1262,\n",
            "           1.2651],\n",
            "         [-0.9995,  1.3547, -0.2252, -0.7232,  0.0950, -0.8426,  1.8899,\n",
            "          -0.5490],\n",
            "         [ 1.1009, -2.3592, -0.3524,  0.4804, -0.1009, -0.0606,  0.5487,\n",
            "           0.7431]]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ],
      "source": [
        "out = layer_norm.forward(inputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TSUGdHwL6yD2",
        "outputId": "e38f4032-4a80-477c-d0d7-ff64fe0b13e9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor(-1.4901e-08, grad_fn=<MeanBackward0>),\n",
              " tensor(1.0215, grad_fn=<StdBackward0>))"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "out[0].mean(), out[0].std()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "TF_PT_Rec_System",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.21"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
